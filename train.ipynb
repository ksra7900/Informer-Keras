{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15aea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:38:31.947954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759147711.964766   29313 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759147711.970356   29313 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759147711.983157   29313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759147711.983176   29313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759147711.983178   29313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759147711.983179   29313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-29 15:38:31.987876: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from Informer import Informer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d3b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, date, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    seq_date = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X[i:i+window_size])\n",
    "        seq_date.append(date[i:i+window_size])\n",
    "        seq_y.append(y[i+window_size])\n",
    "\n",
    "    return np.array(seq_X), np.array(seq_y), np.array(seq_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acfb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df= pd.read_csv('Data/Tetuan City power consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481c6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create date dataset\n",
    "df_date= pd.DataFrame()\n",
    "df['DateTime']= pd.to_datetime(df['DateTime'])\n",
    "df_date['minute']= df['DateTime'].dt.minute\n",
    "df_date['hour']= df['DateTime'].dt.hour\n",
    "df_date['weekday']= df['DateTime'].dt.weekday\n",
    "df_date['month']= df['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330706a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and prepare data & target \n",
    "df_data= df.drop(['DateTime', 'Zone 1 Power Consumption'], axis=1)\n",
    "df_target= df[['Zone 1 Power Consumption']]\n",
    "\n",
    "# power scaler\n",
    "Power_scaler= PowerTransformer(method='box-cox')\n",
    "df_data['normed_general diffuse flows'] = Power_scaler.fit_transform(df_data[['general diffuse flows']])\n",
    "df_data['normed_diffuse flows'] = Power_scaler.fit_transform(df_data[['diffuse flows']])\n",
    "df_data['normed_humidity'] = np.clip(df_data['Humidity'], a_min=40, a_max=90)\n",
    "df_data = df_data.drop(['Humidity', 'general diffuse flows', 'diffuse flows'], axis=1)\n",
    "\n",
    "# MinMax scaler\n",
    "MinMax_scaler= MinMaxScaler(feature_range=(0, 1))\n",
    "df_data= MinMax_scaler.fit_transform(df_data)\n",
    "df_target= MinMax_scaler.fit_transform(df_target)\n",
    "\n",
    "# sequencing data\n",
    "data, target, date= create_sequences(df_data, df_target, df_date.values, window_size=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f76cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759147714.932021   29313 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2541 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-09-29 15:38:34.933407: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 421521408 exceeds 10% of free system memory.\n",
      "2025-09-29 15:38:35.323936: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 90326016 exceeds 10% of free system memory.\n",
      "2025-09-29 15:38:35.367023: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 421521408 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# prepare date\n",
    "date_df = pd.DataFrame(date.reshape(-1, date.shape[-1]),\n",
    "                       columns=['minute', 'hour', 'weekday', 'month'])\n",
    "\n",
    "\n",
    "date_used = date_df[['hour', 'weekday', 'month']].values\n",
    "date_used = date_used.reshape(date.shape[0], date.shape[1], 3)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((data, date_used), target))\n",
    "\n",
    "# train/val/test split\n",
    "train_size = int(0.7 * len(data))\n",
    "val_size = int(0.15 * len(data))\n",
    "\n",
    "train_ds = dataset.take(train_size).batch(32).shuffle(100)\n",
    "val_ds = dataset.skip(train_size).take(val_size).batch(32)\n",
    "test_ds = dataset.skip(train_size + val_size).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ae6c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:38:35.684725: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 421521408 exceeds 10% of free system memory.\n",
      "2025-09-29 15:38:35.848810: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 90326016 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'context_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# آموزش\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ارزیابی\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/inspect.py:3273\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3271\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3184\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required\u001b[39m\u001b[38;5;132;01m{argtype}\u001b[39;00m\u001b[38;5;124m argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3185\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mname, argtype\u001b[38;5;241m=\u001b[39margtype)\n\u001b[0;32m-> 3186\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3188\u001b[0m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[1;32m   3189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'context_time'"
     ]
    }
   ],
   "source": [
    "# تعریف مدل\n",
    "model = Informer(d_model=64, num_heads=4)  # مقادیر رو بسته به منابع تغییر بده\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# آموزش\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=10)\n",
    "\n",
    "# ارزیابی\n",
    "model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
